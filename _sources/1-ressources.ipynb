{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bien choisir les ressources\n",
    "Il y a plusieurs ressources informatiques qui vous sont disponibles à\n",
    "l'Alliance de recherche numérique du Canada :\n",
    "* Calcul haute performance\n",
    "  * Béluga, Cedar, Graham, Narval, Niagara\n",
    "* Stockage\n",
    "  * Temporaire, projet, *nearline*, dépôt de données de recherche\n",
    "* Infonuagique\n",
    "  * Arbutus, Béluga, Cedar, Graham\n",
    "\n",
    "Le principal but de ce chapitre est de vous permettre d'analyser\n",
    "vos besoins en **ressources de calcul haute performance**, et ce,\n",
    "dans le but de choisir les ressources nécessaires pour votre projet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rappel - le calcul haute performance\n",
    "* Lorsqu'il est question de lancer une **grande quantité de calculs**\n",
    "(séquentiels ou parallèles) ou de **traitements de données**,\n",
    "l'utilisation d'une grappe de calcul haute performance devient nécessaire.\n",
    "* Puisque les **ressources sont partagées** et en grande demande,\n",
    "chaque tâche doit être soumise à un ordonnanceur de tâches.\n",
    "* Il devient donc nécessaire **d'estimer à l'avance les ressources**\n",
    "qui seront réservées lors de l'exécution d'un calcul.\n",
    "\n",
    "Dans cette section, on cherche à évaluer le comportement d'une tâche de calcul\n",
    "afin d'estimer et d'optimiser les ressources à réserver sur la grappe de calcul."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectif - construction d'un script de tâche Slurm\n",
    "Un script de tâche pour [l'ordonnanceur Slurm](https://slurm.schedmd.com/documentation.html) est typiquement un script Bash dans lequel on retrouve :\n",
    "* Le [shebang](https://fr.wikipedia.org/wiki/Shebang) en toute première ligne. Par exemple : `#!/bin/bash`\n",
    "* Les options `#SBATCH` en entête pour les besoins de la tâche. Les options en entête seront lues par la commande de soumission de tâche [`sbatch`](https://slurm.schedmd.com/sbatch.html)\n",
    "* [Chargement des modules](https://docs.computecanada.ca/wiki/Utiliser_des_modules) requis\n",
    "* Les commandes Bash qui seront exécutées automatiquement sur des processeurs réservés pour la tâche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par exemple : [`scripts/mpi-allo.sh`](https://github.com/calculquebec/cip201-serveurs-calcul/blob/main/scripts/mpi-allo.sh)\n",
    "\n",
    "```Bash\n",
    "cat scripts/mpi-allo.sh\n",
    "```\n",
    "```\n",
    "#!/bin/bash\n",
    "#SBATCH --ntasks=10\n",
    "#SBATCH --mem-per-cpu=1000M\n",
    "#SBATCH --time=0-00:10\n",
    "\n",
    "mpirun printenv HOSTNAME OMPI_COMM_WORLD_RANK OMPI_COMM_WORLD_SIZE\n",
    "```\n",
    "\n",
    "Notre documentation à cet effet débute à la page : [Exécuter des tâches](https://docs.computecanada.ca/wiki/Running_jobs/fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des calculs à petite échelle\n",
    "Lorsqu'une tâche de calcul est en cours d'exécution, vous pouvez surveiller différentes métriques :\n",
    "* Utilisation CPU (et GPU, s'il y a lieu)\n",
    "* Mémoire résidente (réellement utilisée)\n",
    "* Mémoire virtuelle (allouée)\n",
    "* Les accès au stockage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sous Windows\n",
    "* [Gestionnaire des tâches Windows](https://fr.wikipedia.org/wiki/Gestionnaire_des_t%C3%A2ches_Windows)\n",
    "* Pour le faire afficher :\n",
    "  * Raccourcis clavier Ctrl+Alt+Suppr ou cliquer sur la barre des tâches avec le bouton droit\n",
    "  * Cliquer sur l'option *Gestionnaire des tâches*\n",
    "\n",
    "![Aperçu du gestionnaire des tâches Windows](images/win-task-manager.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sous Mac OS\n",
    "* [Moniteur d’activité](https://support.apple.com/fr-ca/guide/activity-monitor/actmntr1001/mac)\n",
    "* Pour le faire afficher :\n",
    "  * Démarrer l'application à partir des *Applications et Utilitaires* de Mac OS\n",
    "  * Sinon, utiliser le raccourcis clavier Commande+Espace et taper les premières lettres de \"Moniteur d'activité\" pour pouvoir sélectionner cette application\n",
    "\n",
    "![Aperçu du moniteur d'activité Mac OS](https://help.apple.com/assets/5FDCF1894EB74318147EC0CF/5FDCF18A4EB74318147EC0D6/fr_CA/ad6337d66061aa27122e75521960fc5a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sous Linux\n",
    "Dans un terminal Unix, on peut utiliser :\n",
    "* La [commande `top`](https://man7.org/linux/man-pages/man1/top.1.html) (`q` pour quitter)\n",
    "\n",
    "![Capture de top](images/linux-top.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La [commande `htop`](https://man7.org/linux/man-pages/man1/htop.1.html) (`q` pour quitter)\n",
    "\n",
    "![Capture de htop](images/linux-htop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sur la grappe de calcul directement\n",
    "Avec votre accès par défaut, vous avez un compte de calcul `def-*` de base\n",
    "vous permettant de lancer des tâches de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ressources utilisées d'une tâche terminée\n",
    "```Bash\n",
    "ssh login1\n",
    "...\n",
    "```\n",
    "**Note** : pour accéder aux grappes de calcul en production,\n",
    "il vaut mieux utiliser [une paire de clés SSH](https://docs.computecanada.ca/wiki/Using_SSH_keys_in_Linux/fr)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour soumettre un script, on fait :\n",
    "```Bash\n",
    "sbatch scripts/blastn-gen-seq.sh\n",
    "```\n",
    "\n",
    "Pour voir l'état de la tâche, on ferait :\n",
    "```Bash\n",
    "squeue -u $USER  # ou 'sq'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec la commande [`sacct`](https://slurm.schedmd.com/sacct.html), on peut obtenir un tableau de nos tâches exécutées depuis minuit.\n",
    "```Bash\n",
    "sacct\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec la commande [`seff`](https://docs.computecanada.ca/wiki/Running_jobs/fr#T.C3.A2ches_termin.C3.A9es),\n",
    "on peut obtenir un court rapport d'exécution de tâche.\n",
    "Ce rapport inclut une mesure du temps écoulé, une mesure du temps CPU\n",
    "et une mesure de consommation maximale de la mémoire-vive.\n",
    "Des valeurs d'efficacité en pourcentages sont données pour les cycles CPU\n",
    "et la mémoire-vives en fonction des quantités réservées.\n",
    "```Bash\n",
    "seff <No_tâche>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ressources utilisées par une tâche CPU en cours\n",
    "Étant donné un certain calcul matriciel dans le script Python \n",
    "[`scripts/crunch.py`](https://github.com/calculquebec/cip201-serveurs-calcul/blob/main/scripts/crunch.py) :\n",
    "\n",
    "```Bash\n",
    "less scripts/crunch.py   # q pour quitter\n",
    "```\n",
    "\n",
    "Lors d'une tâche interactive, on peut utiliser `top` et `htop` pour surveiller les ressources utilisées :\n",
    "\n",
    "```Bash\n",
    "# Tâche interactive et installation de modules Python\n",
    "salloc --gres=gpu:1 --ntasks-per-node=4 --mem=8000M --time=0:9:0\n",
    "less scripts/installer/cupy_tmp.sh  # q pour quitter\n",
    "bash scripts/installer/cupy_tmp.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Bash\n",
    "# Exécution avec un processeur\n",
    "less scripts/crunch-1cpu.sh  # q pour quitter\n",
    "bash scripts/crunch-1cpu.sh  # q pour quitter\n",
    "\n",
    "# Exécution avec 4 processeurs\n",
    "less scripts/crunch-4cpu.sh  # q pour quitter\n",
    "bash scripts/crunch-4cpu.sh  # q pour quitter\n",
    "\n",
    "# Comparer les résultats\n",
    "grep sec *.log\n",
    "\n",
    "exit  # Pour revenir à login1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ressources utilisées par une tâche GPU en cours\n",
    "```Bash\n",
    "# Tâche interactive et installation de modules Python\n",
    "salloc --gres=gpu:1 --ntasks-per-node=4 --mem=8000M --time=0:9:0\n",
    "bash scripts/installer/cupy_tmp.sh\n",
    "```\n",
    "\n",
    "* Pour Windows et Mac OS, il existe des outils propriétaires permettant de visualiser en temps réel l'utilisation du GPU. Veuillez vous référer au site Web du manufacturier de votre GPU pour les détails\n",
    "* Sous Linux, il y a d'abord la [commande `nvidia-smi`](https://developer.nvidia.com/nvidia-system-management-interface)\n",
    "\n",
    "```Bash\n",
    "nvidia-smi\n",
    "```\n",
    "\n",
    "![Capture nvidia-smi](images/nvidia-smi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Il existe aussi un projet [`nvtop`](https://github.com/Syllo/nvtop) permettant de visualiser l'utilisation d'un ou plusieurs GPUs dans un terminal\n",
    "\n",
    "```Bash\n",
    "# Exécution avec 1 GPU\n",
    "less scripts/crunch-1gpu.sh  # q pour quitter\n",
    "bash scripts/crunch-1gpu.sh  # q pour quitter\n",
    "\n",
    "# Regarder le résultat\n",
    "less tg.log    # q pour quitter\n",
    "\n",
    "exit  # Pour revenir à login1\n",
    "```\n",
    "\n",
    "![Capture nvtop](https://raw.githubusercontent.com/Syllo/nvtop/master/screenshot/NVTOP_ex1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparer la vitesse CPU vs GPU\n",
    "Avant d'utiliser massivement les GPUs d'une grappe de calcul, il faut tout d'abord que l'application ou l'algorithme puisse démontrer une \"bonne performance\" en utilisant plusieurs processeurs en parallèle.\n",
    "\n",
    "Quelques définitions :\n",
    "* **Temps écoulé** = temps d'exécution total que l'on perçoit et non le temps CPU\n",
    "* **Accélération** = (temps avec un processeur) / (temps avec parallélisme)\n",
    "* **Efficacité** = (Accélération) / (nombre de processeurs)\n",
    "\n",
    "Le coût d'un noeud GPU étant de quatre à cinq fois supérieur à celui d'un noeud régulier, l'utilisation d'un seul GPU doit permettre une accélération d'au moins quatre fois (4x) la vitesse de huit (8) à douze (12) processeurs.\n",
    "* **Accélération** = (temps avec 8 à 12 processeurs) / (temps avec un accélérateur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice - Calcul d'accélération et d'efficacité\n",
    "En supposant les résultats suivants pour un programme parallèle lancé sur $n$ processeurs :\n",
    "\n",
    "```Bash\n",
    "grep sec t*.log\n",
    "```\n",
    "\n",
    "|$n$ proc.|temp (s)|\n",
    "|:-------:|:------:|\n",
    "|    1    |  9.876 |\n",
    "|    4    |  5.220 |\n",
    "\n",
    "Étant donné le script [`scripts/calc-acc-eff.sh`](https://github.com/calculquebec/cip201-serveurs-calcul/blob/main/scripts/calc-acc-eff.sh) :\n",
    "```Bash\n",
    "bash scripts/calc-acc-eff.sh 1:9.876 4:5.220\n",
    "bash scripts/calc-acc-eff.sh 1:9.876 8:0.035\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrapoler les ressources nécessaires\n",
    "### Efficacité cible du calcul parallèle\n",
    "* Une efficacité de 80%, voire 90%, devrait être un seuil minimal pour les tâches parallèles. Or, il existe un **nombre maximal de processeurs** à utiliser pour respecter ce seuil :\n",
    "  * Voir la figure dans la page [loi d'Amdahl](https://fr.wikipedia.org/wiki/Loi_d%27Amdahl)\n",
    "  * Matériel en extra [ici](extra/loi-Amdahl.ipynb)\n",
    "* On vise aussi une consommation en mémoire-vive de l'ordre de 80% de ce qui est demandé à l'ordonnanceur Slurm\n",
    "\n",
    "Rappel - vous pouvez obtenir ces pourcentages via les commandes `sacct -X` (surtout pour obtenir les numéros de tâches) et `seff`. Les valeurs à considérer sont :\n",
    "* `CPU Utilized` et `CPU Efficiency`\n",
    "* `Memory Utilized` et `Memory Efficiency`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taille des données et nombre de fichiers à traiter\n",
    "Pour un calcul donné, il y a deux métriques de stockage à considérer :\n",
    "1. La **quantité** totale en octets (ou Go)\n",
    "1. Le **nombre** total de fichiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour obtenir ces informations :\n",
    "* **Sous Windows** : dans l'explorateur Windows (raccourcis clavier : Windows + E)\n",
    "  * Sélectionner un dossier ou plusieurs fichiers\n",
    "  * Bouton droit de la souris -> *Propriétés*\n",
    "\n",
    "![Windows data properties](images/win-data-size.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Sous Mac OS** : dans *Finder*\n",
    "  * Sélectionner un dossier ou plusieurs fichiers\n",
    "  * Bouton droit de la souris -> *Get Info*\n",
    "  * Autrement : avec l'affichage *Par liste*\n",
    "    * [Activer *Calculer toutes les tailles*](https://www.solutionenligne.org/comment-afficher-taille-dossiers-fichiers-dans-finder-mac-os/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Sous Linux** :\n",
    "  * L'environnement graphique peut offrir le même genre d'outils, mais tout dépend de la distribution et du bureau.\n",
    "  * La commande `du -bs DOSSIER` (`b` : taille apparente en octets, `s` : somme totale) calcule récursivement et affiche la taille totale en octets. La taille apparente est celle qui importe lors d'un transfert ou d'une sauvegarde de données.\n",
    "  * La commande `find DOSSIER | wc -l` compte récursivement et affiche le nombre de fichiers et de sous-dossiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stockage en mémoire selon les types de base\n",
    "En ayant une idée de la taille des données à traiter,\n",
    "il devient possible d'estimer l'espace que les données prendront en mémoire-vive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dans un fichier texte, **chaque caractère** prend de un (1) à deux (2) octets, en moyenne.\n",
    "Cependant, pour certaines langues, l'encodage\n",
    "[UTF-8](https://fr.wikipedia.org/wiki/UTF-8#Description)\n",
    "peut se rendre jusqu'à quatre (4) octets par caractère.\n",
    "Pour les langues latines et germaniques, on peut considérer **deux (2) octets** par caractère.\n",
    "Par exemple, dans une session Python :\n",
    "\n",
    "```Bash\n",
    "python\n",
    "```\n",
    "\n",
    "```Python\n",
    ">>> import sys\n",
    ">>> euro = \"\"\n",
    ">>> sys.getsizeof(euro)\n",
    "49\n",
    ">>> euro = \"Euro\"\n",
    ">>> sys.getsizeof(euro)\n",
    "53\n",
    ">>> euro = \"€\"\n",
    ">>> sys.getsizeof(euro)\n",
    "76\n",
    ">>> euro *= 2  # Donc \"€€\"\n",
    ">>> sys.getsizeof(euro)\n",
    "78\n",
    ">>> quit()  # ou Ctrl+D pour sortir\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Les **nombres entiers** prennent typiquement 2 octets (16 bits), 4 octets (32 bits) ou 8 octets (64 bits) chacun. Tout dépend de la [plage de valeurs souhaitée](https://en.wikipedia.org/wiki/C_data_types#Main_types) :\n",
    "  * 2 octets : ~65 milles valeurs de $0$ à $65535$, ou de $-32767$ à $32767$\n",
    "  * 4 octets : ~4 milliards de valeurs de 0 à $(2^{32}-1)$ ou de $-(2^{31}-1)$ à $(2^{31}-1)$\n",
    "  * 8 octets : ~18 trillions de valeurs de 0 à $(2^{64}-1)$ ou de $-(2^{63}-1)$ à $(2^{63}-1)$\n",
    "\n",
    "```Bash\n",
    "module load python scipy-stack\n",
    "python\n",
    "```\n",
    "\n",
    "```Python\n",
    ">>> import sys\n",
    ">>> import numpy as np\n",
    ">>> cube = np.zeros((100,100,100), dtype=np.int64)\n",
    ">>> sys.getsizeof(cube)\n",
    "8000136\n",
    ">>> cube = np.zeros((100,100,100), dtype=np.int32)\n",
    ">>> sys.getsizeof(cube)\n",
    "4000136\n",
    ">>> np.iinfo(np.int16)\n",
    "iinfo(min=-32768, max=32767, dtype=int16)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Les **nombres à virgule flottante** prennent typiquement 4 octets (32 bits) ou 8 octets (64 bits) chacun, mais on voit de plus en plus [différents types de données à 2 octets (16 bits)](https://en.wikipedia.org/wiki/Bfloat16_floating-point_format) dans des applications d'apprentissage-machine. Il se peut néanmoins que les données soient initialement en simple ou double précision:\n",
    "  * [simple précision](https://en.wikipedia.org/wiki/Single-precision_floating-point_format) : 4 octets, une résolution de 23 bits (~7 décimales), une échelle de 8 bits (${10}^{-38}$ à ${10}^{38}$)\n",
    "  * [double précision](https://en.wikipedia.org/wiki/Double-precision_floating-point_format) : 8 octets, une résolution de 52 bits (~16 décimales), une échelle de 11 bits (${10}^{-308}$ à ${10}^{308}$)\n",
    "\n",
    "```Python\n",
    ">>> cube = np.ndarray((100,100,100), dtype=np.float32)\n",
    ">>> cube[0,0,0] = np.pi\n",
    ">>> print(cube[0,0,0])\n",
    "3.1415927\n",
    ">>> print(cube[0,0,0], np.pi)\n",
    "3.1415927 3.141592653589793\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Certains langages utilisent systématiquement **8 octets** (64 bits) par nombre.\n",
    "* [Certains compilateurs et certaines bibliothèques](https://en.wikipedia.org/wiki/Quadruple-precision_floating-point_format) peuvent calculer des valeurs représentées avec 128 bits [ou plus](https://gmplib.org/).\n",
    "* Pour les nombres complexes, on multiplie l'espace mémoire par deux (2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple de calcul de l'espace-mémoire :\n",
    "```Python\n",
    ">>> nb_matrices = 3        # Trois matrices C = prod_mat(A, B)\n",
    ">>> taille = 25000         # Matrices carrées\n",
    ">>> octets_par_nombre = 8  # Double précision\n",
    ">>> memoire = nb_matrices * taille*taille * octets_par_nombre\n",
    ">>> memoire / 1000**3\n",
    ">>>\n",
    ">>> quit()  # ou Ctrl+D pour sortir\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### La complexité des algorithmes\n",
    "La question qui se pose : en augmentant la ou les dimensions du problème, quelles devraient être la durée du calcul et la consommation en mémoire-vive?\n",
    "Une [analyse de la complexité de l'algorithme principal](https://fr.wikipedia.org/wiki/Analyse_de_la_complexit%C3%A9_des_algorithmes)\n",
    "permettrait de connaître l'ordre $O$ du calcul en fonction de la taille $n$ des données :\n",
    "\n",
    "* $O(n)$: proportionnel à $n$\n",
    "* $O(n*m)$: représente un calcul à deux (2) dimensions indépendantes\n",
    "* $O(n^3)$: calcul d'ordre cubique\n",
    "* $O(n*m*k^2)$: par exemple, un filtre de taille $k*k$ sur une image $n*m$\n",
    "* $O(n*log(n))$: typique de certains\n",
    "[algorithmes de tri](https://fr.wikipedia.org/wiki/Algorithme_de_tri#Comparaison_des_algorithmes)\n",
    "où il y a $n$ éléments à trier en $log_2(n)$ étapes.\n",
    "\n",
    "Une analyse détaillée du code (s'il est disponible) n'est pas nécessaire pour déterminer le type de calcul qui est fait.\n",
    "* Vous pouvez vous inspirer des données en entrées pour deviner l'ordre du calcul principal. \n",
    "* Vous pouvez mesurer le temps d'exécution en fonction de la taille du problème. En extrapolant les résultats, il serait possible de prévoir le comportement du programme sur une grappe de calcul."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice - Complexité de l'algorithme\n",
    "Dans cet exercice, il est question d'inverser une matrice de valeurs aléatoires de taille $n*n$ :\n",
    "* Soumettre le script [`scripts/inv-mat.sh`](https://github.com/calculquebec/cip201-serveurs-calcul/blob/main/scripts/inv-mat.sh) avec la commande `sbatch` :\n",
    "\n",
    "```Bash\n",
    "sbatch scripts/inv-mat.sh\n",
    "```\n",
    "\n",
    "* Explorer les scripts Python\n",
    "[`scripts/inv-mat.py`](https://github.com/calculquebec/cip201-serveurs-calcul/blob/main/scripts/inv-mat.py) et \n",
    "[`scripts/inv-mat.sh`](https://github.com/calculquebec/cip201-serveurs-calcul/blob/main/scripts/inv-mat.sh) :\n",
    "\n",
    "```Bash\n",
    "cat scripts/inv-mat.py\n",
    "cat scripts/inv-mat.sh\n",
    "```\n",
    "\n",
    "* Suivre l'évolution du calcul avec `squeue -u $USER`, environ aux 30 secondes\n",
    "* Le résultat sera sauvegardé dans le fichier `temps_inv.csv`\n",
    "* Analyse avec Python, Pandas et Numpy dans le script [`scripts/inv-mat-pred.py`](https://github.com/calculquebec/cip201-serveurs-calcul/blob/main/scripts/inv-mat-pred.py) :\n",
    "\n",
    "```Bash\n",
    "module load gcc python scipy-stack\n",
    "\n",
    "cat scripts/inv-mat-pred.py\n",
    "python scripts/inv-mat-pred.py temps_inv.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principales différences entre les grappes de calcul\n",
    "* À propos des grappes :\n",
    "\n",
    "| | [Béluga](https://docs.computecanada.ca/wiki/B%C3%A9luga) | [Cedar](https://docs.computecanada.ca/wiki/Cedar/fr) | [Graham](https://docs.computecanada.ca/wiki/Graham/fr) | [Narval](https://docs.computecanada.ca/wiki/Narval) | [Niagara](https://docs.computecanada.ca/wiki/Niagara/fr) |\n",
    "|-----------------------:|:---------:|:---------:|:---------:|:------------:|:----------:|\n",
    "| **Mise en production** | Mars 2019 | Juin 2017 | Juin 2017 | Octobre 2021 | Avril 2018 |\n",
    "|              **Ville** | Montréal  |  Burnaby  | Waterloo  |   Montréal   |   Toronto  |\n",
    "|           **Province** |  Québec   |    C.-B.  |  Ontario  |    Québec    |   Ontario  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Nombre de processeurs (coeurs CPU) selon le cas :\n",
    "\n",
    "| Processeur Intel/AMD  | [Béluga](https://docs.computecanada.ca/wiki/B%C3%A9luga) | [Cedar](https://docs.computecanada.ca/wiki/Cedar/fr) | [Graham](https://docs.computecanada.ca/wiki/Graham/fr) | [Narval](https://docs.computecanada.ca/wiki/Narval) | [Niagara](https://docs.computecanada.ca/wiki/Niagara/fr) |\n",
    "|----------------------:|:--------:|:--------:|:--------:|:---------:|:---------:|\n",
    "|      Broadwell (avx2) |          | 724 * 32 | 983 * 32 |           |           |\n",
    "|      Skylake (avx512) | 802 * 40 | 640 * 48 |          |           | 1548 * 40 |\n",
    "| Cascade Lake (avx512) |          | 768 * 48 |  72 * 44 |           |  468 * 40 |\n",
    "|      EPYC Rome (avx2) |          |          |          | 1142 * 64 |           |\n",
    "\n",
    "| Mémoire par proc. | [Béluga](https://docs.computecanada.ca/wiki/B%C3%A9luga) | [Cedar](https://docs.computecanada.ca/wiki/Cedar/fr) | [Graham](https://docs.computecanada.ca/wiki/Graham/fr) | [Narval](https://docs.computecanada.ca/wiki/Narval) | [Niagara](https://docs.computecanada.ca/wiki/Niagara/fr) |\n",
    "|-------:|:-----:|:-----:|:-----:|:-----:|:-----:|\n",
    "|  2400M |  6400 |       |       |       |       |\n",
    "|  4000M |       | 86016 | 28896 | 70976 |       |\n",
    "|  4400M |       |       |  3168 |       |       |\n",
    "|  4800M | 23560 |       |       |       | 80960 |\n",
    "|  8000M |       |  3072 |  1792 |       |       |\n",
    "| 16000M |       |   768 |   768 |       |       |\n",
    "| 19200M |  2120 |       |       |       |       |\n",
    "| 32000M |       |       |       |  2112 |       |\n",
    "| 48000M |       |   768 |   192 |       |       |\n",
    "| 96000M |       |   128 |       |       |       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Nombre de GPUs](https://docs.computecanada.ca/wiki/Using_GPUs_with_Slurm/fr) selon le cas :\n",
    "\n",
    "| Accélérateurs | [Béluga](https://docs.computecanada.ca/wiki/B%C3%A9luga) | [Cedar](https://docs.computecanada.ca/wiki/Cedar/fr) | [Graham](https://docs.computecanada.ca/wiki/Graham/fr) | [Mist (Power9)](https://docs.scinet.utoronto.ca/index.php/Mist) | [Narval](https://docs.computecanada.ca/wiki/Narval) |\n",
    "|----------------:|:---:|:---:|:---:|:---:|:---:|\n",
    "| NVIDIA P100 12G |     | 456 | 320 |     |     |\n",
    "| NVIDIA P100 16G |     | 128 |     |     |     |\n",
    "|   NVIDIA T4 16G |     |     | 144 |     |     |\n",
    "| NVIDIA V100 16G | 688 |     |  54 |     |     |\n",
    "| NVIDIA V100 32G |     | 768 |  16 | 216 |     |\n",
    "| NVIDIA A100 40G |     |     |     |     | 632 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Réseau haute-performance et ordonnancement :\n",
    "\n",
    "| | [Béluga](https://docs.computecanada.ca/wiki/B%C3%A9luga) | [Cedar](https://docs.computecanada.ca/wiki/Cedar/fr) | [Graham](https://docs.computecanada.ca/wiki/Graham/fr) | [Narval](https://docs.computecanada.ca/wiki/Narval) | [Niagara](https://docs.computecanada.ca/wiki/Niagara/fr) |\n",
    "|------------------------:|:----------:|:-----------:|:----------:|:-----------:|:----------:|\n",
    "|        Connexion rapide | InfiniBand |   OmniPath  | InfiniBand | InfiniBand  | InfiniBand |\n",
    "|               Topologie |  En arbre  |   En arbre  |  En arbre  |  En arbre   | DragonFly+ |\n",
    "|     Taille îlots (proc) | 640 à 1200 | 1024 à 1536 |    1024    | 3072 à 3584 |    17280   |\n",
    "|     Facteur de blockage |   max 5:1  |   max 2:1   |   max 8:1  |  max 4.7:1  |   max 2:1  |\n",
    "| Granularité des tâches  | /proc /GPU |  /proc /GPU | /proc /GPU |  /proc /GPU |   /noeud   |\n",
    "|         Durée maximale  |   7 jours  |   28 jours  |  28 jours  |   7 jours   |   1 jour   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Stockage : le tout sera décrit au dernier chapitre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Points à retenir\n",
    "* Prévoir les **paramètres d'une tâche Slurm**\n",
    "  * Nombre de processeurs (CPU) et de noeuds de calcul\n",
    "  * Nombre d'accélérateurs (GPU)\n",
    "  * Quantité de mémoire-vive (RAM)\n",
    "  * Temps du calcul (`JJ-H:M` ou `H:M:S`)\n",
    "* Différents **outils pour surveiller** les ressources utilisées\n",
    "  * `time` et autres bibliothèques de mesure du temps écoulé\n",
    "  * `top`, `htop`, `nvtop`, `nvidia-smi`\n",
    "  * `sacct`, `seff`\n",
    "  * `du -bs`, `find | wc -l` et autres outils du système d'exploitation\n",
    "* On vise une **efficacité de 80%** pour les tâches parallèles CPU\n",
    "  * L'accélération avec un accélérateur (GPU) doit être significative (>4x)\n",
    "* Le choix de la grappe dépend des besoins de chaque type de calcul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
