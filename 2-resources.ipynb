{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Resources Wisely\n",
    "With a Digital Research Alliance of Canada account, you have\n",
    "access to many **high performance computing resources**:\n",
    "* Compute clusters:\n",
    "  * BÃ©luga, Cedar, Graham, Narval, Niagara\n",
    "* Storage :\n",
    "  * Temporary, project, *nearline*\n",
    "\n",
    "While being large, but still limited in size, these resources\n",
    "should be used carefully by everyone in order to maximise the\n",
    "amount of produced scientific results for themselves and for others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal - Writing a Proper Job Script for Slurm\n",
    "The main goal of this chapter is to teach you how to\n",
    "analyze your compute tasks in order to **determine the\n",
    "required resources** to run tasks on compute clusters.\n",
    "Each compute task will eventually be defined\n",
    "in a **job script** to be submitted to the\n",
    "[Slurm scheduler](https://slurm.schedmd.com/documentation.html).\n",
    "Typically written in Bash commands, job scripts have:\n",
    "* A [shebang](https://en.wikipedia.org/wiki/Shebang_(Unix))\n",
    "  at the first line. For example: `#!/bin/bash`\n",
    "* A header of `#SBATCH` options for the job's requirements.\n",
    "  These options will be parsed at submission time by the\n",
    "  [`sbatch` command](https://slurm.schedmd.com/sbatch.html)\n",
    "* [Modules](https://docs.alliancecan.ca/wiki/Utiliser_des_modules/en)\n",
    "  loaded before running the compute task\n",
    "* The Bash commands that will be executed\n",
    "  automatically on the reserved resources for the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example : [`scripts/mpi-hello.sh`](https://github.com/calculquebec/cip201-compute-systems/blob/main/scripts/mpi-hello.sh)\n",
    "\n",
    "```Bash\n",
    "cat scripts/mpi-hello.sh\n",
    "```\n",
    "```\n",
    "#!/bin/bash\n",
    "#SBATCH --ntasks=10\n",
    "#SBATCH --mem-per-cpu=1000M\n",
    "#SBATCH --time=0-00:10\n",
    "\n",
    "module load gcc/9.3.0 &> /dev/null\n",
    "\n",
    "mpirun printenv HOSTNAME OMPI_COMM_WORLD_RANK OMPI_COMM_WORLD_SIZE\n",
    "```\n",
    "\n",
    "Our documentation about job scripts starts at this page:\n",
    "[Running jobs](https://docs.alliancecan.ca/wiki/Running_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing Compute Jobs on Your Computer\n",
    "While a compute task is running on your computer,\n",
    "you can monitor different metrics:\n",
    "* CPU usage (and GPU usage, if applicable)\n",
    "* Memory usage\n",
    "* Storage access (IOPS, bandwidth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Windows\n",
    "* [Windows Tasks Manager](https://en.wikipedia.org/wiki/Task_Manager_(Windows))\n",
    "* You can find it in two ways:\n",
    "  * Look for *Task Manager* in the Start menu, or\n",
    "  * With the keyboard shortcut Ctrl+Alt+Delete\n",
    "\n",
    "![Windows 11 Task Manager screenshot](https://upload.wikimedia.org/wikipedia/en/a/ae/Windows_Task_Manager_screenshot.png)\n",
    "_Image from Wikimedia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In macOS\n",
    "* [Activity Monitor](https://support.apple.com/en-ca/guide/activity-monitor/actmntr1001/mac)\n",
    "* To open the Activity Monitor:\n",
    "  * Start it from the *Applications and Utilities* directory in macOS\n",
    "  * Otherwise, use the Command+Space shortcut and start typing\n",
    "    the first letters of \"Activity Monitor\" to find and select it\n",
    "\n",
    "![Overview of Mac OS Activity Monitor](https://help.apple.com/assets/63FD404271C3B6058F265722/63FD404A71C3B6058F265732/en_US/07d6bea6dc9944ae58f6581297196752.png)\n",
    "_Image from Apple Support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Linux\n",
    "In a Linux terminal, you can use:\n",
    "* The [`top` command](https://man7.org/linux/man-pages/man1/top.1.html)\n",
    "  (Press Q to quit)\n",
    "\n",
    "![Screenshot of top](images/linux-top.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The [`htop` command](https://man7.org/linux/man-pages/man1/htop.1.html)\n",
    "  (Press Q to quit)\n",
    "\n",
    "![Screenshot of htop](images/linux-htop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing Compute Jobs on Clusters\n",
    "As a first step, we need to **connect to the cluster**:\n",
    "```Bash\n",
    "ssh login1\n",
    "...\n",
    "```\n",
    "**Notes** :\n",
    "* To connect to the national systems in production, you better use a\n",
    "  [pair of SSH keys](https://docs.alliancecan.ca/wiki/Using_SSH_keys_in_Linux)\n",
    "* [Multifactor authentication](https://docs.alliancecan.ca/wiki/Multifactor_authentication)\n",
    "  is now available on national clusters. See the\n",
    "  [introductory video here](https://www.youtube.com/watch?v=qNsUsZ73HP0)\n",
    "* With your default access, you can use at least one\n",
    "  `def-*` account, which allows you to submit compute jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To submit a job script, we use the\n",
    "[`sbatch` command](https://slurm.schedmd.com/sbatch.html) :\n",
    "```Bash\n",
    "sbatch scripts/blastn-gen-seq.sh\n",
    "```\n",
    "\n",
    "And to monitor the status of a job, we use the\n",
    "[`squeue` command](https://slurm.schedmd.com/squeue.html) :\n",
    "```Bash\n",
    "squeue -u $USER  # or 'sq'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources Used by a Completed Job\n",
    "With the [`sacct` command](https://slurm.schedmd.com/sacct.html),\n",
    "we can get a detailed table of completed jobs since midnight:\n",
    "```Bash\n",
    "sacct\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the [`seff` command](https://docs.alliancecan.ca/wiki/Running_jobs#Completed_jobs),\n",
    "we can get a short report about a single completed job.\n",
    "This report includes the elapsed time, the total\n",
    "CPU time and the maximum amount of memory used.\n",
    "Two values of efficiency are given in percentages of total CPU\n",
    "usage and maximum memory usage (compared to requested amounts).\n",
    "```Bash\n",
    "seff <Job_ID>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources Used by a Running Job\n",
    "Given some operations on a 3D matrix in the Python script\n",
    "[`scripts/crunch.py`](https://github.com/calculquebec/cip201-compute-systems/blob/main/scripts/crunch.py) :\n",
    "\n",
    "```Bash\n",
    "cat scripts/crunch.py\n",
    "```\n",
    "\n",
    "While an interactive job is running, we can use the `top`\n",
    "and `htop` commands to monitor resources being used:\n",
    "\n",
    "```Bash\n",
    "# Interactive job\n",
    "salloc --cpus-per-task=4 --mem=8000M --time=0:15:0\n",
    "\n",
    "cat scripts/crunch.sh\n",
    "\n",
    "# Run with one CPU core\n",
    "bash scripts/crunch.sh --cpu 1\n",
    "top -u $USER  # Press Q to quit\n",
    "\n",
    "# Run with four CPU cores\n",
    "bash scripts/crunch.sh --cpu 4\n",
    "htop -u $USER  # Press Q to quit\n",
    "\n",
    "# Compare results\n",
    "grep sec *.log\n",
    "\n",
    "exit  # To go back to login1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use\n",
    "[JupyterHub](https://docs.alliancecan.ca/wiki/JupyterHub)\n",
    "to profile your codes, you can visualize in real time the\n",
    "use of the _Machine Resources_ in the tab _GPU Dashboards_:\n",
    "\n",
    "![GPU Dashboard for CPU](images/nv-dashboard_cpu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exercise** - Checking Resources Used by a Running Job\n",
    "While your job is running, you are allowed to connect by SSH to\n",
    "the corresponding compute node in order to monitor your processes:\n",
    "```Bash\n",
    "cat scripts/inv-mat.sh\n",
    "sbatch scripts/inv-mat.sh\n",
    "```\n",
    "\n",
    "Here are some general steps for job monitoring and validation:\n",
    "* Identify on which node your job is running: `squeue -u $USER`\n",
    "* Connect to that node with: `ssh <node_name>`\n",
    "* Monitor the job execution with `top` or `htop`:\n",
    "  * Are your processes running at **near 100%?**?\n",
    "  * Are your parallel processes running at **near $n$ * 100%**,\n",
    "    where $n$ is the number of reserved CPU cores for the job?\n",
    "  * Does the **compute node** seem fully utilized?\n",
    "* **Inspect results** in `time_inv.csv`\n",
    "  * Identify any problem. If any, find the cause\n",
    "  * Correct the code, the compilation, the script\n",
    "    or the parameters used for the compute task\n",
    "  * Resubmit the compute job and redo the above validation steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Demo) Checking Resources Used by a Running GPU Job\n",
    "```Bash\n",
    "# Interactive job\n",
    "salloc --cpus-per-task=4 --mem=8000M --time=0:15:0 --gres=gpu:1\n",
    "```\n",
    "\n",
    "* For Windows and macOS, you can install proprietary software\n",
    "  that allows real time visualization of the GPU utilization.\n",
    "  Please check the documentation of the GPU manufacturer for details\n",
    "* In Linux, with an NVIDIA GPU, we first have the\n",
    "  [`nvidia-smi` command](https://developer.nvidia.com/nvidia-system-management-interface)\n",
    "\n",
    "```Bash\n",
    "nvidia-smi\n",
    "```\n",
    "\n",
    "![Capture nvidia-smi](images/nvidia-smi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There is also the [`nvtop`](https://github.com/Syllo/nvtop) project\n",
    "  that allows visualizing the use of one or many GPUs in a terminal:\n",
    "\n",
    "```Bash\n",
    "# Run with one GPU\n",
    "bash scripts/crunch.sh --gpu\n",
    "nvtop  # Press Q to quit\n",
    "```\n",
    "![Capture nvtop](https://raw.githubusercontent.com/Syllo/nvtop/master/screenshot/NVTOP_ex1.png)\n",
    "\n",
    "```Bash\n",
    "# Check the result\n",
    "grep sec tg.log\n",
    "\n",
    "exit  # To go back to login1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use\n",
    "[JupyterHub](https://docs.alliancecan.ca/wiki/JupyterHub)\n",
    "to profile your GPU software or code, you can visualize in real\n",
    "time the use of _GPU Resources_ in the tab _GPU Dashboards_:\n",
    "\n",
    "![GPU Dashboards for GPU](images/nv-dashboard_gpu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exercise** - Testing `crunch.py` with One GPU\n",
    "```Bash\n",
    "cat    scripts/crunch-sbatch-1gpu.sh\n",
    "sbatch scripts/crunch-sbatch-1gpu.sh\n",
    "\n",
    "squeue -u $USER  # To check the status of the job\n",
    "tail -24 $(ls slurm-* | tail -1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing the Speed of CPU Cores and a GPU\n",
    "Before using GPUs on compute clusters, your application\n",
    "and its main algorithm must at first demonstrate a \"good\n",
    "performance\" while using regular CPU cores in parallel.\n",
    "\n",
    "A few definitions:\n",
    "* **Elapsed time** = total perceived execution time, not the CPU time\n",
    "* **Acceleration** = (Elapsed time with `1` CPU core) /\n",
    "  (Elapsed time with `N` CPU cores)\n",
    "* **Efficiency** = (Acceleration) / `N`\n",
    "\n",
    "The acquisition cost of a GPU node being about five times\n",
    "the cost of a regular CPU node, the use of a single GPU\n",
    "must accelerate an application at least five times (5x)\n",
    "the speed of 8 to 16 cores in parallel to be worth it.\n",
    "* **GPU Acceleration** = (time with 8 to 16 CPU cores) /\n",
    "  (time with a single GPU) >= 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jobs Analysis via Cluster Portals\n",
    "BÃ©luga and Narval each have a great portal for job monitoring:\n",
    "* [https://portail.beluga.calculquebec.ca/](https://portail.beluga.calculquebec.ca/)\n",
    "* [https://portail.narval.calculquebec.ca/](https://portail.narval.calculquebec.ca/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Required Compute Resources\n",
    "### Target Efficiency of a Job\n",
    "When testing with a **short and small job**, the target for:\n",
    "* The **compute efficiency** is **at least 90%**\n",
    "  * Serial tasks: may need to **optimize the access to the data**\n",
    "    * Use each type of storage spaces adequately (see chapter 4)\n",
    "  * Parallel tasks: there is a **maximum number\n",
    "    of CPU cores** that can reach this target:\n",
    "    * [Scalability](https://docs.alliancecan.ca/wiki/Scalability)\n",
    "      principle and the\n",
    "      [Amdahl's law](https://en.wikipedia.org/wiki/Amdahl%27s_law)\n",
    "* The **memory usage** should be around **80%**\n",
    "  of what was requested to the Slurm scheduler\n",
    "\n",
    "**Reminder** - you can get these percentages with the commands\n",
    "`sacct -X` (mainly to get job IDs) and `seff`.\n",
    "The important values are:\n",
    "* `CPU Utilized` and `CPU Efficiency`\n",
    "* `Memory Utilized` and `Memory Efficiency`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exercise** - Job Efficiency\n",
    "For some of your jobs listed by the following command:\n",
    "```Bash\n",
    "sacct -X\n",
    "```\n",
    "Get the `CPU Efficiency` and the `Memory Efficiency` with the command:\n",
    "```Bash\n",
    "seff <Job_ID>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrapolating Required Compute Resources\n",
    "**If you increase the size of the problem**, what\n",
    "should be the expected compute time and memory usage?\n",
    "[A detailed code analysis](https://en.wikipedia.org/wiki/Analysis_of_algorithms)\n",
    "is not necessary to make that approximation:\n",
    "\n",
    "* You can **measure the execution time** (with the\n",
    "  `time` command) in function of the size of the problem.\n",
    "  By extrapolating the results, you should be able to\n",
    "  predict the program behavior on the compute cluster.\n",
    "\n",
    "```Bash\n",
    "time -p sleep 2\n",
    "```\n",
    "\n",
    "* You can also considerate the **shape of the input data**\n",
    "  in order to guess the order of the main calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Size and Number of Files to Process\n",
    "On top of the compute time and memory usage, you must also considerate\n",
    "the **storage space usage**. Values to take into account are:\n",
    "1. The **quantity** in bytes (or GB)\n",
    "    * Can be used to **estimate** the memory usage\n",
    "    * Take into account the size limit of the\n",
    "      **local storage** for optimized file access\n",
    "1. The **number** of files to process\n",
    "    * **Data parallelism** could be a solution\n",
    "    * **Multiply the average run time** needed to process a file by\n",
    "      the total number of files to get an approximate job time limit\n",
    "    * **Multiply the average size of files** by their number to\n",
    "      estimate the space needed in memory (example: loading images)\n",
    "    * Use the local storage to **optimize\n",
    "      repetitive and random accesses**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the number of files and the total size:\n",
    "* **In Windows**: in Windows Explorer (keyboard shorcut: Windows + E)\n",
    "  * Select one directory or multiple files\n",
    "  * Right-click -> Select *Properties*\n",
    "\n",
    "![Windows data properties](images/win-data-size.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **In macOS**: with *Finder*\n",
    "  * Select one directory or multiple files\n",
    "  * Right-click -> Select *Get Info*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **In Linux** and on **compute clusters**:\n",
    "  * The graphical environment can provide similar tools, but\n",
    "    it depends on the Linux distribution and the chosen desktop\n",
    "  * The command `du -sb DIRECTORY` (`s` for total sum, `b` for\n",
    "    apparent size in bytes) recursively computes and displays\n",
    "    the total size of used space in bytes. The apparent size is\n",
    "    important to considerate while transferring or backuping the data\n",
    "  * The command `find DIRECTORY | wc -l` recursively counts\n",
    "    and displays the number of files and subdirectories\n",
    "\n",
    "```Bash\n",
    "du -sb data\n",
    "find data | wc -l\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Compute Clusters\n",
    "* About compute clusters:\n",
    "\n",
    "| | [BÃ©luga](https://docs.alliancecan.ca/wiki/B%C3%A9luga/en) | [Cedar](https://docs.alliancecan.ca/wiki/Cedar) | [Graham](https://docs.alliancecan.ca/wiki/Graham) | [Narval](https://docs.alliancecan.ca/wiki/Narval/en) | [Niagara](https://docs.alliancecan.ca/wiki/Niagara) |\n",
    "|-----------------:|:----------:|:---------:|:---------:|:------------:|:----------:|\n",
    "| **Availability** | March 2019 | June 2017 | June 2017 | October 2021 | April 2018 |\n",
    "|         **City** |  MontrÃ©al  |  Burnaby  | Waterloo  |   MontrÃ©al   |   Toronto  |\n",
    "|     **Province** |   QuÃ©bec   |    B.C.   |  Ontario  |    QuÃ©bec    |   Ontario  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Number of CPU cores (number of nodes * CPU cores per node) :\n",
    "\n",
    "|     AMD/Intel CPU     | [BÃ©luga](https://docs.alliancecan.ca/wiki/B%C3%A9luga/en) | [Cedar](https://docs.alliancecan.ca/wiki/Cedar) | [Graham](https://docs.alliancecan.ca/wiki/Graham) | [Narval](https://docs.alliancecan.ca/wiki/Narval/en) | [Niagara](https://docs.alliancecan.ca/wiki/Niagara) |\n",
    "|----------------------:|:--------:|:--------:|:--------:|:---------:|:---------:|\n",
    "|      Broadwell (avx2) |          | 724 * 32 | 983 * 32 |           |           |\n",
    "|      Skylake (avx512) | 802 * 40 | 640 * 48 |          |           | 1548 * 40 |\n",
    "| Cascade Lake (avx512) |          | 768 * 48 | 136 * 44 |           |  476 * 40 |\n",
    "|      EPYC Rome (avx2) |          |          |          | 1181 * 64 |           |\n",
    "\n",
    "| Memory per core | [BÃ©luga](https://docs.alliancecan.ca/wiki/B%C3%A9luga/en) | [Cedar](https://docs.alliancecan.ca/wiki/Cedar) | [Graham](https://docs.alliancecan.ca/wiki/Graham) | [Narval](https://docs.alliancecan.ca/wiki/Narval/en) | [Niagara](https://docs.alliancecan.ca/wiki/Niagara) |\n",
    "|-------:|:--------:|:---------:|:--------:|:---------:|:---------:|\n",
    "|  2400M | 160 * 40 |           |          |           |           |\n",
    "|  4000M |          | 1408 * 48 | 903 * 32 | 1145 * 64 |           |\n",
    "|  4000M |          |  576 * 32 |          |           |           |\n",
    "|  4400M |          |           | 136 * 44 |           |           |\n",
    "|  4800M | 589 * 40 |           |          |           | 2024 * 40 |\n",
    "|  8000M |          |   96 * 32 |  56 * 32 |           |           |\n",
    "| 16000M |          |   24 * 32 |  24 * 32 |           |           |\n",
    "| 19200M |  53 * 40 |           |          |           |           |\n",
    "| 32000M |          |           |          |   36 * 64 |           |\n",
    "| 48000M |          |   24 * 32 |   3 * 64 |           |           |\n",
    "| 96000M |          |    4 * 32 |          |           |           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Number of GPUs](https://docs.alliancecan.ca/wiki/Using_GPUs_with_Slurm)\n",
    "  per cluster:\n",
    "\n",
    "| GPU Model | [BÃ©luga](https://docs.alliancecan.ca/wiki/B%C3%A9luga/en) | [Cedar](https://docs.alliancecan.ca/wiki/Cedar) | [Graham](https://docs.alliancecan.ca/wiki/Graham) | [Mist (Power9)](https://docs.scinet.utoronto.ca/index.php/Mist) | [Narval](https://docs.alliancecan.ca/wiki/Narval/en) |\n",
    "|----------------:|:---:|:---:|:---:|:---:|:---:|\n",
    "| NVIDIA P100 12G |     | 456 | 320 |     |     |\n",
    "| NVIDIA P100 16G |     | 128 |     |     |     |\n",
    "|   NVIDIA T4 16G |     |     | 144 |     |     |\n",
    "| NVIDIA V100 16G | 688 |     |  54 |     |     |\n",
    "| NVIDIA V100 32G |     | 768 |  16 | 216 |     |\n",
    "| NVIDIA A100 40G |     |     |     |     | 636 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Other specifications :\n",
    "\n",
    "| | [BÃ©luga](https://docs.alliancecan.ca/wiki/B%C3%A9luga/en) | [Cedar](https://docs.alliancecan.ca/wiki/Cedar) | [Graham](https://docs.alliancecan.ca/wiki/Graham) | [Narval](https://docs.alliancecan.ca/wiki/Narval/en) | [Niagara](https://docs.alliancecan.ca/wiki/Niagara) |\n",
    "|---------------------:|:----------:|:---------:|:----------:|:----------:|:----------:|\n",
    "|         Fast network | InfiniBand | OmniPath  | InfiniBand | InfiniBand | InfiniBand |\n",
    "|             Topology |  Fat Tree  | Fat Tree  |  Fat Tree  |  Fat Tree  | DragonFly+ |\n",
    "|   Island size (core) |  640-1200  | 1024-1536 |    1024    | 3072-3584  |    17280   |\n",
    "|      Blocking factor |  max 5:1   |  max 2:1  |  max 8:1   | max 4.7:1  |   max 2:1  |\n",
    "| Job granularity (by) | core, GPU  | core, GPU | core, GPU  |  core, GPU |    node    |\n",
    "|         Maximum time |   7 days   |  28 days  |   7 days   |   7 days   |   1 day    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Storage: all will be described in the last chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Points\n",
    "* PrÃ©voir les **paramÃ¨tres d'une tÃ¢che Slurm**\n",
    "  * Nombre de processeurs (CPU) et de noeuds de calcul\n",
    "  * Nombre d'accÃ©lÃ©rateurs (GPU)\n",
    "  * QuantitÃ© de mÃ©moire-vive (RAM)\n",
    "  * Temps du calcul (`JJ-H:M` ou `H:M:S`)\n",
    "* DiffÃ©rents **outils pour surveiller** les ressources utilisÃ©es\n",
    "  * `time` et autres bibliothÃ¨ques de mesure du temps Ã©coulÃ©\n",
    "  * `top`, `htop`, `nvtop`, `nvidia-smi`\n",
    "  * `sacct`, `seff`\n",
    "  * `du -sb`, `find | wc -l` et autres outils du systÃ¨me d'exploitation\n",
    "* On vise une **efficacitÃ© de 90%** et plus pour les tÃ¢ches CPU\n",
    "  * L'accÃ©lÃ©ration avec un accÃ©lÃ©rateur (GPU) doit Ãªtre significative (>5x)\n",
    "* Le choix de la grappe dÃ©pend des besoins de chaque type de calcul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
