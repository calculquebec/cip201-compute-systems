{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Resources Wisely\n",
    "With a Digital Research Alliance of Canada account, you have\n",
    "access to many **high performance computing resources**:\n",
    "* Compute clusters:\n",
    "  * Béluga, Cedar, Graham, Narval, Niagara\n",
    "* Storage :\n",
    "  * Temporary, project, *nearline*\n",
    "\n",
    "While being large, but still limited in size, these resources\n",
    "should be used carefully by everyone in order to maximise the\n",
    "amount of produced scientific results for themselves and for others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal - Writing a Proper Job Script for Slurm\n",
    "The main goal of this chapter is to teach you how to\n",
    "analyze your compute tasks in order to **determine the\n",
    "required resources** to run tasks on compute clusters.\n",
    "Each compute task will eventually be defined\n",
    "in a **job script** to be submitted to the\n",
    "[Slurm scheduler](https://slurm.schedmd.com/documentation.html).\n",
    "Typically written in Bash commands, job scripts have:\n",
    "* A [shebang](https://en.wikipedia.org/wiki/Shebang_(Unix))\n",
    "  at the first line. For example: `#!/bin/bash`\n",
    "* A header of `#SBATCH` options for the job's requirements.\n",
    "  These options will be parsed at submission time by the\n",
    "  [`sbatch` command](https://slurm.schedmd.com/sbatch.html)\n",
    "* [Modules](https://docs.alliancecan.ca/wiki/Utiliser_des_modules/en)\n",
    "  loaded before running the compute task\n",
    "* The Bash commands that will be executed\n",
    "  automatically on the reserved resources for the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example : [`scripts/mpi-hello.sh`](https://github.com/calculquebec/cip201-compute-systems/blob/main/scripts/mpi-hello.sh)\n",
    "\n",
    "```Bash\n",
    "cat scripts/mpi-hello.sh\n",
    "```\n",
    "```\n",
    "#!/bin/bash\n",
    "#SBATCH --ntasks=10\n",
    "#SBATCH --mem-per-cpu=1000M\n",
    "#SBATCH --time=0-00:10\n",
    "\n",
    "module load gcc/9.3.0 &> /dev/null\n",
    "\n",
    "mpirun printenv HOSTNAME OMPI_COMM_WORLD_RANK OMPI_COMM_WORLD_SIZE\n",
    "```\n",
    "\n",
    "Our documentation about job scripts starts at this page:\n",
    "[Running jobs](https://docs.alliancecan.ca/wiki/Running_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing Compute Jobs on Your Computer\n",
    "While a compute task is running on your computer,\n",
    "you can monitor different metrics:\n",
    "* CPU usage (and GPU usage, if applicable)\n",
    "* Memory usage\n",
    "* Storage access (IOPS, bandwidth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Windows\n",
    "* [Windows Tasks Manager](https://en.wikipedia.org/wiki/Task_Manager_(Windows))\n",
    "* You can find it in two ways:\n",
    "  * Look for *Task Manager* in the Start menu, or\n",
    "  * With the keyboard shortcut Ctrl+Alt+Delete\n",
    "\n",
    "![Windows 11 Task Manager screenshot](https://upload.wikimedia.org/wikipedia/en/a/ae/Windows_Task_Manager_screenshot.png)\n",
    "_Image from Wikimedia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In macOS\n",
    "* [Activity Monitor](https://support.apple.com/en-ca/guide/activity-monitor/actmntr1001/mac)\n",
    "* To open the Activity Monitor:\n",
    "  * Start it from the *Applications and Utilities* directory in macOS\n",
    "  * Otherwise, use the Command+Space shortcut and start typing\n",
    "    the first letters of \"Activity Monitor\" to find and select it\n",
    "\n",
    "![Overview of Mac OS Activity Monitor](https://help.apple.com/assets/63FD404271C3B6058F265722/63FD404A71C3B6058F265732/en_US/07d6bea6dc9944ae58f6581297196752.png)\n",
    "_Image from Apple Support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Linux\n",
    "In a Linux terminal, you can use:\n",
    "* The [`top` command](https://man7.org/linux/man-pages/man1/top.1.html)\n",
    "  (Press Q to quit)\n",
    "\n",
    "![Screenshot of top](images/linux-top.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The [`htop` command](https://man7.org/linux/man-pages/man1/htop.1.html)\n",
    "  (Press Q to quit)\n",
    "\n",
    "![Screenshot of htop](images/linux-htop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing Compute Jobs on Clusters\n",
    "On commence par **se connecter au noeud frontal** de la grappe :\n",
    "```Bash\n",
    "ssh login1\n",
    "...\n",
    "```\n",
    "**Notes** :\n",
    "* Pour accéder aux grappes de calcul en production, il vaut mieux\n",
    "  utiliser [une paire de clés SSH](https://docs.alliancecan.ca/wiki/Using_SSH_keys_in_Linux/fr).\n",
    "* [L'authentification multifacteur](https://docs.alliancecan.ca/wiki/Multifactor_authentication/fr)\n",
    "  est maintenant offerte sur les grappes nationales.\n",
    "  [Vidéo d'introduction ici](https://www.youtube.com/watch?v=ciycOUbchl8).\n",
    "* Avec votre accès par défaut, vous avez un compte de calcul\n",
    "  `def-*` de base qui vous permet de lancer des tâches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To submit a job script, we use the\n",
    "[`sbatch` command](https://slurm.schedmd.com/sbatch.html) :\n",
    "```Bash\n",
    "sbatch scripts/blastn-gen-seq.sh\n",
    "```\n",
    "\n",
    "And to monitor the status of a job, we use the\n",
    "[`squeue` command](https://slurm.schedmd.com/squeue.html) :\n",
    "```Bash\n",
    "squeue -u $USER  # or 'sq'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources Used by a Completed Job\n",
    "With the [`sacct` command](https://slurm.schedmd.com/sacct.html),\n",
    "we can get a detailed table of completed jobs since midnight:\n",
    "```Bash\n",
    "sacct\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the [`seff` command](https://docs.alliancecan.ca/wiki/Running_jobs#Completed_jobs),\n",
    "we can get a short report about a single completed job.\n",
    "This report includes the elapsed time, the total\n",
    "CPU time and the maximum amount of memory used.\n",
    "Two values of efficiency are given in percentages of total CPU\n",
    "usage and maximum memory usage (compared to requested amounts).\n",
    "```Bash\n",
    "seff <Job_ID>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources Used by a Running Job\n",
    "Given some operations on a 3D matrix in the Python script\n",
    "[`scripts/crunch.py`](https://github.com/calculquebec/cip201-compute-systems/blob/main/scripts/crunch.py) :\n",
    "\n",
    "```Bash\n",
    "cat scripts/crunch.py\n",
    "```\n",
    "\n",
    "While an interactive job is running, we can use the `top`\n",
    "and `htop` commands to monitor resources being used:\n",
    "\n",
    "```Bash\n",
    "# Interactive job\n",
    "salloc --cpus-per-task=4 --mem=8000M --time=0:15:0\n",
    "\n",
    "cat scripts/crunch.sh\n",
    "\n",
    "# Run with one CPU core\n",
    "bash scripts/crunch.sh --cpu 1\n",
    "top -u $USER  # Press Q to quit\n",
    "\n",
    "# Run with four CPU cores\n",
    "bash scripts/crunch.sh --cpu 4\n",
    "htop -u $USER  # Press Q to quit\n",
    "\n",
    "# Compare results\n",
    "grep sec *.log\n",
    "\n",
    "exit  # To go back to login1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use\n",
    "[JupyterHub](https://docs.alliancecan.ca/wiki/JupyterHub)\n",
    "to profile your codes, you can visualize in real time the\n",
    "use of the _Machine Resources_ in the tab _GPU Dashboards_:\n",
    "\n",
    "![GPU Dashboard for CPU](images/nv-dashboard_cpu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exercise** - Checking Resources Used by a Running Job\n",
    "While your job is running, you are allowed to connect by SSH to\n",
    "the corresponding compute node in order to monitor your processes:\n",
    "```Bash\n",
    "cat scripts/inv-mat.sh\n",
    "sbatch scripts/inv-mat.sh\n",
    "```\n",
    "\n",
    "Here are some general steps for job monitoring and validation:\n",
    "* Identify on which node your job is running: `squeue -u $USER`\n",
    "* Connect to that node with: `ssh <node_name>`\n",
    "* Monitor the job execution with `top` or `htop`:\n",
    "  * Are your processes running at **near 100%?**?\n",
    "  * Are your parallel processes running at **near $n$ * 100%**,\n",
    "    where $n$ is the number of reserved CPU cores for the job?\n",
    "  * Does the **compute node** seem fully utilized?\n",
    "* **Inspect results** in `time_inv.csv`\n",
    "  * Identify any problem. If any, find the cause\n",
    "  * Correct the code, the compilation, the script\n",
    "    or the parameters used for the compute task\n",
    "  * Resubmit the compute job and redo the above validation steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Demo) Checking Resources Used by a Running GPU Job\n",
    "```Bash\n",
    "# Interactive job\n",
    "salloc --cpus-per-task=4 --mem=8000M --time=0:15:0 --gres=gpu:1\n",
    "```\n",
    "\n",
    "* For Windows and Mac OS, you can install proprietary software\n",
    "  that allows real time visualization of the GPU utilization.\n",
    "  Please check the documentation of the GPU manufacturer for details\n",
    "* In Linux, with an NVIDIA GPU, we first have the\n",
    "  [`nvidia-smi` command](https://developer.nvidia.com/nvidia-system-management-interface)\n",
    "\n",
    "```Bash\n",
    "nvidia-smi\n",
    "```\n",
    "\n",
    "![Capture nvidia-smi](images/nvidia-smi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There is also the [`nvtop`](https://github.com/Syllo/nvtop) project\n",
    "  that allows visualizing the use of one or many GPUs in a terminal:\n",
    "\n",
    "```Bash\n",
    "# Run with one GPU\n",
    "bash scripts/crunch.sh --gpu\n",
    "nvtop  # Press Q to quit\n",
    "```\n",
    "![Capture nvtop](https://raw.githubusercontent.com/Syllo/nvtop/master/screenshot/NVTOP_ex1.png)\n",
    "\n",
    "```Bash\n",
    "# Check the result\n",
    "grep sec tg.log\n",
    "\n",
    "exit  # To go back to login1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use\n",
    "[JupyterHub](https://docs.alliancecan.ca/wiki/JupyterHub)\n",
    "to profile your GPU software or code, you can visualize in real\n",
    "time the use of _GPU Resources_ in the tab _GPU Dashboards_:\n",
    "\n",
    "![GPU Dashboards for GPU](images/nv-dashboard_gpu.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exercise** - Testing `crunch.py` with One GPU\n",
    "```Bash\n",
    "cat    scripts/crunch-sbatch-1gpu.sh\n",
    "sbatch scripts/crunch-sbatch-1gpu.sh\n",
    "\n",
    "squeue -u $USER  # To check the status of the job\n",
    "tail -24 $(ls slurm-* | tail -1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing the Speed of CPU Cores and a GPU\n",
    "Avant d'utiliser massivement les GPUs d'une grappe de calcul, il faut\n",
    "tout d'abord que l'application ou l'algorithme puisse démontrer une\n",
    "\"bonne performance\" en utilisant plusieurs processeurs en parallèle.\n",
    "\n",
    "Quelques définitions :\n",
    "* **Temps écoulé** = temps d'exécution total que l'on perçoit et non le temps CPU\n",
    "* **Accélération** = (temps avec un processeur) / (temps avec parallélisme)\n",
    "* **Efficacité** = (Accélération) / (nombre de processeurs)\n",
    "\n",
    "Le coût d'un noeud GPU étant cinq fois supérieur à celui d'un noeud\n",
    "régulier, l'utilisation d'un seul GPU doit permettre une accélération\n",
    "d'au moins cinq fois (5x) la vitesse de huit (8) à douze (12) processeurs.\n",
    "* **Accélération** = (temps avec 8 à 12 processeurs) / (temps avec un accélérateur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jobs Analysis via Cluster Portals\n",
    "Béluga et Narval ont chacun un portail pour l'analyse des tâches :\n",
    "* [https://portail.beluga.calculquebec.ca/](https://portail.beluga.calculquebec.ca/)\n",
    "* [https://portail.narval.calculquebec.ca/](https://portail.narval.calculquebec.ca/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Required Compute Resources\n",
    "### Target Efficiency of a Job\n",
    "À coût d'essais et erreurs avec une **tâche de petite taille**,\n",
    "la cible pour :\n",
    "* **Le calcul** est une **efficacité d'au moins 90%**\n",
    "  * Tâches séquentielles : il faut **optimiser les accès aux données**\n",
    "    * Utiliser adéquatement les différents types de stockage\n",
    "  * Tâches parallèles : il existe un **nombre maximal de processeurs**\n",
    "    à utiliser pour respecter ce seuil :\n",
    "    * Principe de [scalabilité](https://docs.alliancecan.ca/wiki/Scalability/fr)\n",
    "      et [Loi d'Amdahl](https://fr.wikipedia.org/wiki/Loi_d%27Amdahl)\n",
    "* **La mémoire-vive** est une consommation **de l'ordre de 80%**\n",
    "  de ce qui est demandé à l'ordonnanceur Slurm\n",
    "\n",
    "**Rappel** - vous pouvez obtenir ces pourcentages via les commandes\n",
    "`sacct -X` (surtout pour obtenir les numéros de tâches) et `seff`.\n",
    "Les valeurs à considérer sont :\n",
    "* `CPU Utilized` et `CPU Efficiency`\n",
    "* `Memory Utilized` et `Memory Efficiency`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exercise** - Job Efficiency\n",
    "For some of your jobs listed by the following command:\n",
    "```Bash\n",
    "sacct -X\n",
    "```\n",
    "Get the `CPU Efficiency` and the `Memory Efficiency` with the command:\n",
    "```Bash\n",
    "seff <Job_ID>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrapolating Required Compute Resources\n",
    "La question qui se pose :\n",
    "**en augmentant la ou les dimensions du problème**, quelles devraient\n",
    "  être la durée du calcul et la consommation en mémoire-vive?\n",
    "[Une analyse détaillée du code](https://fr.wikipedia.org/wiki/Analyse_de_la_complexit%C3%A9_des_algorithmes)\n",
    "n'est pas nécessaire pour déterminer le type de calcul qui est fait :\n",
    "\n",
    "* Vous pouvez **mesurer le temps d'exécution** (avec la\n",
    "  commande `time`) en fonction de la taille du problème.\n",
    "  En extrapolant les résultats, il serait possible de prévoir\n",
    "  le comportement du programme sur une grappe de calcul.\n",
    "\n",
    "```Bash\n",
    "time -p sleep 2\n",
    "```\n",
    "\n",
    "* Vous pouvez considérer le **format des données en entrées** pour\n",
    "  deviner l'ordre du calcul principal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Size and Number of Files to Process\n",
    "En plus du temps de calcul et de l'espace mémoire, il faut aussi\n",
    "considérer **l'utilisation du stockage**. Les valeurs à tenir compte :\n",
    "1. La **quantité** en octets (ou Go)\n",
    "    * Peut servir à **estimer** l'utilisation de la mémoire-vive\n",
    "    * Tenir compte de la taille du **stockage local rapide** pour\n",
    "      optimiser les accès aux fichiers\n",
    "1. Le **nombre** de fichiers à traiter\n",
    "    * Considérer le **parallélisme de données**\n",
    "    * **Multiplier la durée moyenne** du traitement d'un fichier par\n",
    "      le nombre de fichiers pour estimer la durée d'une tâche\n",
    "    * **Multiplier la taille moyenne** des fichiers par leur nombre\n",
    "      pour estimer l'espace en mémoire-vive (par exemple : des images)\n",
    "    * Utiliser le stockage rapide pour **optimiser les accès**\n",
    "      aléatoires et nombreux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour obtenir le nombre de fichiers et la taille totale :\n",
    "* **Sous Windows** : dans l'explorateur Windows (raccourcis clavier : Windows + E)\n",
    "  * Sélectionner un dossier ou plusieurs fichiers\n",
    "  * Bouton droit de la souris -> *Propriétés*\n",
    "\n",
    "![Windows data properties](images/win-data-size.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Sous Mac OS** : dans *Finder*\n",
    "  * Sélectionner un dossier ou plusieurs fichiers\n",
    "  * Bouton droit de la souris -> *Get Info*\n",
    "  * Autrement : avec l'affichage *Par liste*\n",
    "    * [Activer *Calculer toutes les tailles*](https://www.solutionenligne.org/comment-afficher-taille-dossiers-fichiers-dans-finder-mac-os/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **In Linux** and on **compute clusters** :\n",
    "  * The graphical environment can provide similar tools, but\n",
    "    it depends on the Linux distribution and the chosen desktop\n",
    "  * The command `du -sb DIRECTORY` (`s` for total sum, `b` for\n",
    "    apparent size in bytes) recursively computes and displays\n",
    "    the total size of used space in bytes. The apparent size is\n",
    "    important to consider while transferring or backuping the data\n",
    "  * The command `find DIRECTORY | wc -l` recursively counts\n",
    "    and displays the number of files and subdirectories\n",
    "\n",
    "```Bash\n",
    "du -sb data\n",
    "find data | wc -l\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Compute Clusters\n",
    "* About compute clusters:\n",
    "\n",
    "| | [Béluga](https://docs.alliancecan.ca/wiki/B%C3%A9luga/en) | [Cedar](https://docs.alliancecan.ca/wiki/Cedar) | [Graham](https://docs.alliancecan.ca/wiki/Graham) | [Narval](https://docs.alliancecan.ca/wiki/Narval/en) | [Niagara](https://docs.alliancecan.ca/wiki/Niagara) |\n",
    "|-----------------:|:----------:|:---------:|:---------:|:------------:|:----------:|\n",
    "| **Availability** | March 2019 | June 2017 | June 2017 | October 2021 | April 2018 |\n",
    "|         **City** |  Montréal  |  Burnaby  | Waterloo  |   Montréal   |   Toronto  |\n",
    "|     **Province** |   Québec   |    B.C.   |  Ontario  |    Québec    |   Ontario  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Number of CPU cores (number of nodes * CPU cores per node) :\n",
    "\n",
    "|     AMD/Intel CPU     | [Béluga](https://docs.alliancecan.ca/wiki/B%C3%A9luga/en) | [Cedar](https://docs.alliancecan.ca/wiki/Cedar) | [Graham](https://docs.alliancecan.ca/wiki/Graham) | [Narval](https://docs.alliancecan.ca/wiki/Narval/en) | [Niagara](https://docs.alliancecan.ca/wiki/Niagara) |\n",
    "|----------------------:|:--------:|:--------:|:--------:|:---------:|:---------:|\n",
    "|      Broadwell (avx2) |          | 724 * 32 | 983 * 32 |           |           |\n",
    "|      Skylake (avx512) | 802 * 40 | 640 * 48 |          |           | 1548 * 40 |\n",
    "| Cascade Lake (avx512) |          | 768 * 48 | 136 * 44 |           |  476 * 40 |\n",
    "|      EPYC Rome (avx2) |          |          |          | 1181 * 64 |           |\n",
    "\n",
    "| Memory per core | [Béluga](https://docs.alliancecan.ca/wiki/B%C3%A9luga/en) | [Cedar](https://docs.alliancecan.ca/wiki/Cedar) | [Graham](https://docs.alliancecan.ca/wiki/Graham) | [Narval](https://docs.alliancecan.ca/wiki/Narval/en) | [Niagara](https://docs.alliancecan.ca/wiki/Niagara) |\n",
    "|-------:|:--------:|:---------:|:--------:|:---------:|:---------:|\n",
    "|  2400M | 160 * 40 |           |          |           |           |\n",
    "|  4000M |          | 1408 * 48 | 903 * 32 | 1145 * 64 |           |\n",
    "|  4000M |          |  576 * 32 |          |           |           |\n",
    "|  4400M |          |           | 136 * 44 |           |           |\n",
    "|  4800M | 589 * 40 |           |          |           | 2024 * 40 |\n",
    "|  8000M |          |   96 * 32 |  56 * 32 |           |           |\n",
    "| 16000M |          |   24 * 32 |  24 * 32 |           |           |\n",
    "| 19200M |  53 * 40 |           |          |           |           |\n",
    "| 32000M |          |           |          |   36 * 64 |           |\n",
    "| 48000M |          |   24 * 32 |   3 * 64 |           |           |\n",
    "| 96000M |          |    4 * 32 |          |           |           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Number of GPUs](https://docs.alliancecan.ca/wiki/Using_GPUs_with_Slurm)\n",
    "  per cluster:\n",
    "\n",
    "| GPU Model | [Béluga](https://docs.alliancecan.ca/wiki/B%C3%A9luga/en) | [Cedar](https://docs.alliancecan.ca/wiki/Cedar) | [Graham](https://docs.alliancecan.ca/wiki/Graham) | [Mist (Power9)](https://docs.scinet.utoronto.ca/index.php/Mist) | [Narval](https://docs.alliancecan.ca/wiki/Narval/en) |\n",
    "|----------------:|:---:|:---:|:---:|:---:|:---:|\n",
    "| NVIDIA P100 12G |     | 456 | 320 |     |     |\n",
    "| NVIDIA P100 16G |     | 128 |     |     |     |\n",
    "|   NVIDIA T4 16G |     |     | 144 |     |     |\n",
    "| NVIDIA V100 16G | 688 |     |  54 |     |     |\n",
    "| NVIDIA V100 32G |     | 768 |  16 | 216 |     |\n",
    "| NVIDIA A100 40G |     |     |     |     | 636 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Other specifications :\n",
    "\n",
    "| | [Béluga](https://docs.alliancecan.ca/wiki/B%C3%A9luga/en) | [Cedar](https://docs.alliancecan.ca/wiki/Cedar) | [Graham](https://docs.alliancecan.ca/wiki/Graham) | [Narval](https://docs.alliancecan.ca/wiki/Narval/en) | [Niagara](https://docs.alliancecan.ca/wiki/Niagara) |\n",
    "|---------------------:|:----------:|:---------:|:----------:|:----------:|:----------:|\n",
    "|         Fast network | InfiniBand | OmniPath  | InfiniBand | InfiniBand | InfiniBand |\n",
    "|             Topology |  Fat Tree  | Fat Tree  |  Fat Tree  |  Fat Tree  | DragonFly+ |\n",
    "|   Island size (core) |  640-1200  | 1024-1536 |    1024    | 3072-3584  |    17280   |\n",
    "|      Blocking factor |  max 5:1   |  max 2:1  |  max 8:1   | max 4.7:1  |   max 2:1  |\n",
    "| Job granularity (by) | core, GPU  | core, GPU | core, GPU  |  core, GPU |    node    |\n",
    "|         Maximum time |   7 days   |  28 days  |   7 days   |   7 days   |   1 day    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Storage: all will be described in the last chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Points\n",
    "* Prévoir les **paramètres d'une tâche Slurm**\n",
    "  * Nombre de processeurs (CPU) et de noeuds de calcul\n",
    "  * Nombre d'accélérateurs (GPU)\n",
    "  * Quantité de mémoire-vive (RAM)\n",
    "  * Temps du calcul (`JJ-H:M` ou `H:M:S`)\n",
    "* Différents **outils pour surveiller** les ressources utilisées\n",
    "  * `time` et autres bibliothèques de mesure du temps écoulé\n",
    "  * `top`, `htop`, `nvtop`, `nvidia-smi`\n",
    "  * `sacct`, `seff`\n",
    "  * `du -sb`, `find | wc -l` et autres outils du système d'exploitation\n",
    "* On vise une **efficacité de 90%** et plus pour les tâches CPU\n",
    "  * L'accélération avec un accélérateur (GPU) doit être significative (>5x)\n",
    "* Le choix de la grappe dépend des besoins de chaque type de calcul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
